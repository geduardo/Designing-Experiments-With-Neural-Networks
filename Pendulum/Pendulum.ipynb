{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendulum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are given a simple gravity pendulum of length $L$ and mass\n",
    "$M$ and the goal is to find the oscillation period on Earth's surface. We know\n",
    "the period is a function only of the length $L$ and the value of the Earth's\n",
    "gravity (which we assume to be constant): $T \\approx 2\\pi\\sqrt{\\frac{L}{g}}$, so\n",
    "the value of the mass $M$ is irrelevant for the purpose, but in principle this\n",
    "is unknown to the agent. In this set-up, we give the experimenter two possible\n",
    "actions to take (but only one try): either measuring the mass $M$ (eg. by using\n",
    "a calibrated spring) or measuring the length $L$ of the string (e.g by using a\n",
    "calibrated ruler). When the experimenter takes an action over the environment,\n",
    "it produces an outcome (either the mass $M$ or the length $L$). This outcome is\n",
    "passed to the analyzer which tries to make a guess of the period based on the\n",
    "value of the outcome of experimenter's action. Then the empirical period of the\n",
    "pendulum is observed and compared to the value predicted by the analyzer.\n",
    "Depending on the result of the comparison a loss and a reward are generated to\n",
    "train the experimenter and the analyzer. In general: the closer the value of the\n",
    "prediction to the empirical value the smaller the loss and the higher the\n",
    "reward. After the iteration is completed, a new pendulum with new values of $M$\n",
    "and $L$ (ideally generated uniformly at random under the i.i.d. assumption) are\n",
    "generated and the process starts again.\n",
    "\n",
    "The goal is to form a\n",
    "feedback loop between the experimenter and the analyzer from the, at first\n",
    "unknown, correlations between the outcomes and the values to be predicted. The\n",
    "better the experimenter gets, the better the data available for the analyzer to\n",
    "make better predictions that will generate better rewards for the experimenter.\n",
    "Hopefully, this feedback loop will converge to an optimal experimental strategy\n",
    "and nearly perfect predictions. At the beginning both sub-agents will\n",
    "start by giving random outputs since they are not trained. This is what we call\n",
    "the exploration phase and it is of fundamental importance for the\n",
    "feedback loop to start. It can be artificially enforced, for example with\n",
    "$\\epsilon$-greedy algorithms. If there\n",
    "exists any correlation between the choices of the experimenter and the target\n",
    "value to be predicted, the analyzer's training algorithm (usually some version\n",
    "of the gradient descent) can exploit those correlations to start the descent to some\n",
    "local or global minimum.\n",
    "\n",
    "Now, let us define an experimenter. In this case, the experimenter's environment\n",
    "space $\\mathcal{X}$ is the empty set $\\emptyset$, since there is no input. This\n",
    "means that the agent takes the action based solely on the rewards obtained. The\n",
    "action space $\\mathcal{A}$ is just $\\{0,1\\}$, with 0 representing the action of\n",
    "measuring the mass and 1 the action of measuring the length.\n",
    "\n",
    "We can therefore set a very basic decision rule for our experimenter agent:\n",
    "\n",
    "  - We define the value function $Q:\\mathcal{A}\\times\n",
    "  \\mathcal{X}\\rightarrow\\mathbb{R}$ that associates with each action $a \\in\n",
    "  \\mathcal{A}$ a value $Q(x,a)=q_{x,a}$. If $\\mathcal{A}$ and $\\mathcal{X}$ are discrete\n",
    "  spaces we can associate a value table to $Q$ with elements $Q(x,a)$. In the \n",
    "  case where $\\mathcal{X}$ is $\\emptyset$, the value table is just a vector \n",
    "  $\\mathbb{\\textbf{Q}}=(q_0,q_1,...,q_{k})$, where $k$ is the number of elements\n",
    "  in $\\mathcal{A}.$\n",
    "  - In every episode, the agent takes an action $a$ and receives a reward $r$\n",
    "  after taking the action.\n",
    "  The update rule for $\\textbf{Q}$ is the following:\n",
    "  \\begin{equation}\n",
    "    q_a\\leftarrow q_a + r\n",
    "    \\label{update_rule1}\n",
    "  \\end{equation}\n",
    "  This is, the value $q_a$ is just the cumulative reward obtained by the \n",
    "  action $a$.\n",
    "  - The agent's policy $\\mathscr{E}:\\emptyset  \\rightarrow \\mathcal{A}$ or \n",
    "  decision rule is:\n",
    "  \\begin{equation}\n",
    "    a = argmax_{\\lambda \\in \\mathcal{A}} Q(\\lambda)\n",
    "  \\end{equation}\n",
    "  \n",
    "  This is, the experimenter takes the action $a$ with the highest $q_a$, and \n",
    "  $\\mathscr{E}$ is trained by updating $\\textbf{Q}$ each episode.\n",
    "\n",
    "Note that the choice is just to illustrate that we can\n",
    "build reinforcement learning agents with very simple rules. We could have\n",
    "chosen instead of the cumulative reward the average reward obtained with the \n",
    "action, but the working principle would be identical.\n",
    "\n",
    "However, our policy is still flawed, since the first action that gets a reward\n",
    "would always be selected afterwards independently of its optimality. To solve\n",
    "this, we can force the agent to initially explore different options ignoring the\n",
    "decision rule, and slowly, when the values $q_a$ are more reliable, let the\n",
    "agent choose according to the policy. The easiest way to achieve this\n",
    "is with an $\\epsilon$-greedy decision algorithm: we set an exploration rate\n",
    "$\\epsilon$ that decreases in each episode until it reaches a minimum value\n",
    "$\\epsilon_\\text{min}\\geq 0$. The experimenter is set to take the policy \n",
    "with probability $P_{\\text{greedy}}=1-\\epsilon$ and a\n",
    "random action with a probability $P_{\\text{random}}=\\epsilon$. We have the\n",
    "freedom to choose how to decrease the value of $\\epsilon$, and it may have a\n",
    "crucial impact on the training. A very popular rule is to decrease the value\n",
    "constantly by subtracting $\\delta_\\epsilon = 1/N$, where $N$ is the number\n",
    "iterations of the training. So in each episode:\n",
    "\\begin{align}\n",
    "  &\\text{if}\\; \\; \\epsilon > \\epsilon_\\text{min} \\;\\;\\; &\\epsilon&\\leftarrow\\epsilon - \\delta_\\epsilon \\\\\n",
    "  &\\text{else} \\; \\;  &\\epsilon &\\leftarrow \\epsilon_\\text{min}\n",
    "\\end{align} \n",
    "\n",
    "\n",
    "For the analyzer, we set a trainable real function $\\mathscr{A}: S \\rightarrow\n",
    "\\mathbb{R}$. We can use any trainable function, but to keep it simple let's use\n",
    "a regular feed-forward neural network with one hidden layer of two neurons,\n",
    "trained with the gradient descent algorithm and the Mean\n",
    "Squared Error (MSE) loss.\n",
    "\n",
    "We need now to define how to calculate the reward.  In our case we want the\n",
    "reward function to be high when the analyzer predicts a period $T_\\text{pred}$\n",
    "close to the real period of the pendulum and low when the period prediction is\n",
    "far. So, ideally we would like a function that:\n",
    "\\begin{align}\n",
    "       r(T_{\\text{pred}} \\approx T) &\\approx 1\\\\\n",
    "       r(T_{\\text{pred}}>> T \\text{ or } T_{\\text{pred}} << T) & \\approx 0\n",
    "\\end{align}\n",
    "One natural way to achieve this is using a Gaussian distribution over the\n",
    "relative error $\\Delta=(T-T_{\\text{pred}})/T$. This is:\n",
    "\\begin{equation}\n",
    "   r(\\Delta)=\\exp\\left(-\\frac{1}{2}\\left( \\frac{\\Delta}{\\sigma} \\right) ^2\\right)\n",
    "  \\label{gaussian_reward}\n",
    "\\end{equation}\n",
    "and $\\sigma$ allows us to modify the precision we want in order to obtain a \n",
    "reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We set the path to import the modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "from copy import copy\n",
    "sns.set()\n",
    "# We import the agents and the environment from the \n",
    "# modules created in advance.\n",
    "from modules.analyzers import Two_Neurons\n",
    "from modules.experimenters import Simple_Experimenter\n",
    "from modules.environments import Pendulum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 episodes(100.0%)\n",
      "Elapsed time: 0 min 43s\n",
      "Est. completion time: 0 min 43s,\n",
      "        Est. remaining time: 0 min 0s\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M</th>\n",
       "      <th>L</th>\n",
       "      <th>Action</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Reward</th>\n",
       "      <th>Predicted T</th>\n",
       "      <th>Empirical T</th>\n",
       "      <th>q0</th>\n",
       "      <th>q1</th>\n",
       "      <th>Exploration rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8761</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3398</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.1700</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1228</td>\n",
       "      <td>0.1716</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1716</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.7038</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6005</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6005</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.5466</td>\n",
       "      <td>1.8991</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.7539</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4984</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.2918</td>\n",
       "      <td>1.7427</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6867</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0247</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>2.0363</td>\n",
       "      <td>1.9877</td>\n",
       "      <td>270.8612</td>\n",
       "      <td>4741.0537</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0.8721</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4129</td>\n",
       "      <td>0.5484</td>\n",
       "      <td>1.2190</td>\n",
       "      <td>1.2897</td>\n",
       "      <td>270.8612</td>\n",
       "      <td>4741.6021</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.3885</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4867</td>\n",
       "      <td>0.7230</td>\n",
       "      <td>1.3438</td>\n",
       "      <td>1.4002</td>\n",
       "      <td>270.8612</td>\n",
       "      <td>4742.3252</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.5844</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7907</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>1.7620</td>\n",
       "      <td>1.7847</td>\n",
       "      <td>270.8612</td>\n",
       "      <td>4743.2935</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0.1552</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>1.9252</td>\n",
       "      <td>1.9197</td>\n",
       "      <td>270.8612</td>\n",
       "      <td>4744.2920</td>\n",
       "      <td>-0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           M       L  Action  Outcome  Reward  Predicted T  Empirical T  \\\n",
       "0     0.8761  0.3398       1   0.3398  0.0000       0.0000       1.1700   \n",
       "1     0.1228  0.1716       1   0.1716  0.0000      -0.7038       0.8315   \n",
       "2     0.6005  0.8953       0   0.6005  0.0000      -0.5466       1.8991   \n",
       "3     0.4984  0.7539       0   0.4984  0.0000      -0.2918       1.7427   \n",
       "4     0.6867  0.2573       1   0.2573  0.0000      -0.0247       1.0180   \n",
       "...      ...     ...     ...      ...     ...          ...          ...   \n",
       "9995  0.4528  0.9808       1   0.9808  0.8872       2.0363       1.9877   \n",
       "9996  0.8721  0.4129       1   0.4129  0.5484       1.2190       1.2897   \n",
       "9997  0.3885  0.4867       1   0.4867  0.7230       1.3438       1.4002   \n",
       "9998  0.5844  0.7907       1   0.7907  0.9681       1.7620       1.7847   \n",
       "9999  0.1552  0.9148       1   0.9148  0.9984       1.9252       1.9197   \n",
       "\n",
       "            q0         q1  Exploration rate  \n",
       "0       0.0000     0.0000            1.0000  \n",
       "1       0.0000     0.0000            0.9999  \n",
       "2       0.0000     0.0000            0.9997  \n",
       "3       0.0000     0.0000            0.9996  \n",
       "4       0.0000     0.0000            0.9995  \n",
       "...        ...        ...               ...  \n",
       "9995  270.8612  4741.0537           -0.0001  \n",
       "9996  270.8612  4741.6021           -0.0001  \n",
       "9997  270.8612  4742.3252           -0.0001  \n",
       "9998  270.8612  4743.2935           -0.0001  \n",
       "9999  270.8612  4744.2920           -0.0001  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONSTANTS, INSTANTIATIONS, INITIALIZATION ===============================\n",
    "N_Episodes = 10000 # Number of episodes to train \n",
    "count = 0 # Initialization of a counter\n",
    "# We instantiate the classes of each element\n",
    "experimenter = Simple_Experimenter(iterations=N_Episodes, output_size=2)\n",
    "analyzer = Two_Layers_single_output(input_size=1,learning_rate=0.1)\n",
    "env = Pendulum()\n",
    "# Save time for verbose purposes\n",
    "t0 = time.time()\n",
    "t1 = time.time()\n",
    "\n",
    "# First random initialization of the variables. This part is needed since \n",
    "# some recurrent parts of the loop need from some data to start with.\n",
    "action = experimenter.get_next_action()\n",
    "outcome = env.take_action(action)\n",
    "y_predicted = [0]\n",
    "reward = 0\n",
    "\n",
    "# Auxiliar variables for collecting data\n",
    "values = []\n",
    "df=pd.DataFrame(columns = ['M','L', 'Action', 'Outcome', 'Reward', \n",
    "                           'Predicted T', 'Empirical T', 'q0','q1','Exploration rate'])\n",
    "total_reward_list = []\n",
    "\n",
    "# MAIN LOOP =================================================================\n",
    "\n",
    "while count < N_Episodes:\n",
    "    values.append([env.M, env.L, \n",
    "                   action, outcome, float(reward),\n",
    "                   y_predicted[0], env.T, float(experimenter.Q[0]), float(experimenter.Q[1]), experimenter.exploration_rate])\n",
    "    total_reward_list.append(env.total_reward)\n",
    "    env.restart_values()\n",
    "    action = experimenter.get_next_action()\n",
    "    outcome = env.take_action(action)\n",
    "    measurements = env.get_measurements(outcome)\n",
    "    X, y = env.reshape_for_analyzer(measurements, env.T)\n",
    "    y_predicted = analyzer.predict(X)[0]\n",
    "    reward = env.give_reward(y_predicted, env.T)\n",
    "    experimenter.train(action, reward)\n",
    "    analyzer.train(X, y)\n",
    "# Display training status....................................................\n",
    "    count = count + 1\n",
    "    refresh_rate = 20\n",
    "    if count % (N_Episodes/refresh_rate) == 0:\n",
    "        clear_output()\n",
    "        t2 = time.time()\n",
    "        m, s = divmod(t2-t1, 60)\n",
    "        mt, st = divmod(t2-t0, 60)\n",
    "        me, se = divmod(((t2-t0)/count)*N_Episodes, 60)\n",
    "        mr, sr = divmod(((t2-t0)/count)*N_Episodes-t2+t0, 60)\n",
    "        print (str(int(count)) + '/' +  str(N_Episodes) + \" episodes\" + \n",
    "               '(' + str(100*count/N_Episodes)+ '%)')\n",
    "        print('Elapsed time: {} min {}s'.format(int(mt), int(st)))\n",
    "        print(\"\"\"Est. completion time: {} min {}s,\n",
    "        Est. remaining time: {} min {}s\"\"\".format(int(me), int(se), int(mr),\n",
    "                                                  int(sr)))\n",
    "        t1 = time.time()\n",
    "print('Training completed!')\n",
    "\n",
    "\n",
    "plt.plot(range(len(total_reward_list)), total_reward_list)\n",
    "plt.axvline(x=experimenter.marker,color='k',linestyle='--')\n",
    "plt.ylabel(\"Cumulative reward\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df=pd.DataFrame(values, columns = ['M','L', 'Action', 'Outcome', 'Reward', \n",
    "                           'Predicted T', 'Empirical T', 'q0','q1', 'Exploration rate'])\n",
    "df.to_csv('data-pendulum.csv')\n",
    "df.round(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "184cdf6e-8a67-43e9-8238-48f1530b039f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
