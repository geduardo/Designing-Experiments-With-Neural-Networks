{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Sensors (Simple)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook contains the code to execute the Two Sensors (Simple) experiment of this project. The basic set up consists on three elements:\n",
    "\n",
    "- An **environment**: A mass $M$ and a infinite horizontal surface with friction coefficient $\\mu$ respect to the mass $M$. This environment automatically shoots a bullet of mass $m$ with a velocity $v$ when an episode is started. The mass $M$ is the only parameter restarted each episode by sampling uniformly at random from the interval $[M_\\text{min}, M_\\text{max}]$. For more information and details, go to the [class documentation](TODO) of this environment. \n",
    "- An **agent** that consists of two sub-agents:\n",
    "    - **Experimenter:** its objective is to decide which actions to take to gather the data. After the automatic shooting we give the agent the choice between two sensors and two tries per episode.\n",
    "        - A low precision but wide range (LPWR) position  sensor. It works as follows: the landing zone is divided into four regions or zones of equal size. Each time the box is shot it lands in one of the zones and this sensor if activated gives as output the middle point of the zone. For example, in the image below this sensor would produce the outcome: $3$, since it's the middle point of the zone $B$. This allows to know roughly where the box landed, but with low accuracy.\n",
    "        - A high precision but narrow range (HPNR) position sensor. It works as follows: to activate it you need to specify a region and if the box landed on the specified region the outcome of the sensor is the exact position of the box, otherwise it outputs a constant negative value (set to $-1$) representing a failed measurement. For example, in the image below if this sensor is placed in the zone $B$ it will output the value of $x$ and if placed in any of the other zones it outputs $-1$.\n",
    "        \n",
    "    - **Analyzer**: the goal of this agent is to process the data collected by the Experimenter and to use it to make predictions about physical properties of the system. In this case the Analyzer takes the actions and the outcomes of the experimenter to make a prediction about the position of the mass $M$ after a test shooting. In this test shooting the velocity of the bullet, known to the analyzer, is sampled uniformly at random from a limited range. \n",
    "\n",
    "<br/><br/><br/><br/>\n",
    "<img src=\"figures/Experiment2.svg\" alt=\"Two Sensor Environment\" style=\"width: 800px;\"/>\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "Note that this set up is slightly different from an usual Reinforcement Learning set up, because the rewards do not come from the environment but from the performance of the agent to predict aspects of the environment. Another perspective to this set up would be to include the Analyzer as another element of the environment. However, assuming that perspective means that we have a environment that changes the reward system dynamically, which can be quite a challenging Reinforcement Learning problem. \n",
    "\n",
    "The goal of the Analyzer is to understand the data provided by the measurements of the Experimenter and unveil the correlation between those measurements and the distance traveled by the mass $M$ in the test shooting. The goal of the Experimenter is to learn the optimal strategy to use the sensors to provide the best possible data to the Analyzer. In this case the strategy is obvious: first to take the LPWR sensor to find in which zone the mass landed, and then to use that information to place the HPNR sensor in that zone. The main difficulty here is that the Experimenter needs to memorize the outcome of the first measurement and use it to choose the second measurement. It requires a dynamical strategy for the experiment instead of a predefined one from the beginning.  \n",
    "\n",
    "## Architecture in detail\n",
    "\n",
    "Now let's take deeper look on the architecture and the learning loop. First let's see the complete logic diagram:\n",
    "\n",
    "<br/><br/><br/><br/>\n",
    "<img src=\"figures/TwoSensorDiagram.svg\" alt=\"Two Senors Diagram \" style=\"width: 800px;\"/>\n",
    "\n",
    "As we can see in the image the steps in an episode are the following:\n",
    "\n",
    "1. Experimenter 1 gets the reward and trains its reinforcement learning model* with the needed information. \n",
    "2. Experimenter 1 takes action 1.\n",
    "3. Environment gives outcome 1.\n",
    "\n",
    "<br/><br/>\n",
    "<img src=\"figures/TwoSensorDiagram(1).svg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "4. Experimenter 2 gets the reward and trains its reinforcement learning model* with the needed information.\n",
    "5. Experimenter 2 takes action 2.\n",
    "6. Environment gives outcome 2.\n",
    "\n",
    "<br/><br/><br/><br/>\n",
    "<img src=\"figures/TwoSensorDiagram(2).svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "7. Environment runs a random training shooting and outputs the bullet velocity and the traveled distance by the box to the Analyzer.\n",
    "8. Analyzer gets all the previous data collected by the experimenters and their actions and uses it together with the data of the random training to fit its model.\n",
    "9. Environment runs a random test shooting and outputs the bullet velocity to the Analyzer and holds the the traveled distance by the box.\n",
    "10. Analyzer gets all the previous data collected by the experimenters and their actions and uses it together with the velocity of the bullet from the random test shooting and makes a prediction about the traveled distance by the box.\n",
    "11. The predicted distance and the real distance are compared and the reward is generated to start the next iteration of the learning loop.\n",
    "\n",
    "<br/><br/><br/><br/>\n",
    "<img src=\"figures/TwoSensorDiagram(3).svg\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "<br/><br/><br/><br/>\n",
    "\n",
    "\n",
    "*In the case of this notebook, the experimenter 1 uses a simple Q-Learning algorithm since it has no input, therefore it only updates the Q-table with the new reward and the last action taken. The experimenter 2 uses a simple Deep Q Network with online training. The state fed to the RL agent for experimenter 2 is the action and outcome obtained by experimenter 1, this is, the tuple (action1, outcome1). It updates the weight of its neural network by using the Deep Q Algorithm with the previous state (old_action1, old_outcome1), the action taken by the Experimenter 2 (action2), the reward obtained after the action2, and the new state resulting from the actions of the Experimenter 1 (action1, outcome1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orchestration\n",
    "\n",
    "In this section we are going to implement the training. The code is explained with in-line comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500000/2500000 episodes(100.0%)\n",
      "Elapsed time: 351 min 44s\n",
      "Est. completion time: 351 min 44s,\n",
      "        Est. remaining time: 0 min 0s\n",
      "Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zone</th>\n",
       "      <th>Exact position</th>\n",
       "      <th>Action 1</th>\n",
       "      <th>Outcome 1</th>\n",
       "      <th>Action 2</th>\n",
       "      <th>Outcome 2</th>\n",
       "      <th>Reward</th>\n",
       "      <th>d_predicted</th>\n",
       "      <th>d_test</th>\n",
       "      <th>Exploration rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>2.570</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.570</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.656</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1.121</td>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.121</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>1.444</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1.067</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.124</td>\n",
       "      <td>0.719</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>2.051</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.185</td>\n",
       "      <td>2.654</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>2.949</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.949</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.318</td>\n",
       "      <td>4.195</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499995</th>\n",
       "      <td>D</td>\n",
       "      <td>7.723</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.723</td>\n",
       "      <td>0.972</td>\n",
       "      <td>2.674</td>\n",
       "      <td>2.642</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499996</th>\n",
       "      <td>B</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.976</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499997</th>\n",
       "      <td>A</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499998</th>\n",
       "      <td>B</td>\n",
       "      <td>2.639</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.639</td>\n",
       "      <td>0.990</td>\n",
       "      <td>4.554</td>\n",
       "      <td>4.522</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499999</th>\n",
       "      <td>A</td>\n",
       "      <td>1.946</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.946</td>\n",
       "      <td>0.961</td>\n",
       "      <td>2.687</td>\n",
       "      <td>2.650</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Zone  Exact position  Action 1  Outcome 1  Action 2  Outcome 2  \\\n",
       "0          B           2.570         4       -1.0         1      2.570   \n",
       "1          A           1.121         2       -1.0         1      1.121   \n",
       "2          A           1.067         3       -1.0         0      1.000   \n",
       "3          B           2.051         1       -1.0         4     -1.000   \n",
       "4          B           2.949         1       -1.0         2      2.949   \n",
       "...      ...             ...       ...        ...       ...        ...   \n",
       "2499995    D           7.723         0        7.0         4      7.723   \n",
       "2499996    B           2.154         0        3.0         2      2.154   \n",
       "2499997    A           0.818         0        1.0         1      0.818   \n",
       "2499998    B           2.639         0        3.0         2      2.639   \n",
       "2499999    A           1.946         0        1.0         1      1.946   \n",
       "\n",
       "         Reward  d_predicted  d_test  Exploration rate  \n",
       "0         0.000        0.000   2.656               1.0  \n",
       "1         0.000       -0.101   1.444               1.0  \n",
       "2         0.000       -0.124   0.719               1.0  \n",
       "3         0.000        0.185   2.654               1.0  \n",
       "4         0.000       -0.318   4.195               1.0  \n",
       "...         ...          ...     ...               ...  \n",
       "2499995   0.972        2.674   2.642              -0.0  \n",
       "2499996   0.453        0.915   0.976              -0.0  \n",
       "2499997   0.189        0.774   0.709              -0.0  \n",
       "2499998   0.990        4.554   4.522              -0.0  \n",
       "2499999   0.961        2.687   2.650              -0.0  \n",
       "\n",
       "[2500000 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IMPORTS ===================================================================\n",
    "# We set the path to import the modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "# We import the necessary packages\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "from keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# We import the agents and the environment from the \n",
    "# modules created in advance.\n",
    "\n",
    "from modules.rlagents import Q_Learning, DQN\n",
    "from modules.analyzers import Two_Layers_single_output\n",
    "from modules.environments import Two_Sensors\n",
    "\n",
    "# CONSTANTS, INSTANTIATIONS, INITIALIZATION ===============================\n",
    "\n",
    "N_Episodes = 2500000 # Number of episodes to train \n",
    "count = 0 # Initialization of a counter\n",
    "\n",
    "# We instantiate the classes of each element\n",
    "env = Two_Sensors() \n",
    "experimenter1 = Q_Learning(iterations=N_Episodes, output_size=5)\n",
    "experimenter2 = DQN(iterations=N_Episodes, input_size=6, output_size=5)\n",
    "analyzer = Two_Layers_single_output(input_size=5)\n",
    "\n",
    "# Save time for verbose purposes\n",
    "t0 = time.time()\n",
    "t1 = time.time()\n",
    "\n",
    "# First random initialization of the variables. This part is needed since \n",
    "# some recurrent parts of the loop need from some data to start with.\n",
    "\n",
    "action1 = experimenter1.get_next_action()\n",
    "outcome1 = env.take_action(action1)\n",
    "action2 = random.randint(0,4)\n",
    "outcome2 = env.position_exact\n",
    "d_test = random.uniform(0.8,8)\n",
    "y_predicted = [0]\n",
    "reward = 0\n",
    "\n",
    "# Auxiliar variables for collecting data\n",
    "values = []\n",
    "df=pd.DataFrame(columns = ['Zone', 'Exact position', 'Action 1', \n",
    "                           'Outcome 1', 'Action 2', 'Outcome 2', 'Reward', \n",
    "                           'd_predicted', 'd_test', 'Exploration rate'])\n",
    "total_reward_list = []\n",
    "\n",
    "# MAIN LOOP =================================================================\n",
    "\n",
    "while count < N_Episodes:\n",
    "    \n",
    "    # Record the data from the previous episode.\n",
    "    if env.position_zone==1:\n",
    "        zone='A'\n",
    "    elif env.position_zone==3:\n",
    "        zone='B'\n",
    "    elif env.position_zone==5:\n",
    "        zone='C'\n",
    "    elif env.position_zone==7:\n",
    "        zone='D'\n",
    "    values.append([zone, env.position_exact, \n",
    "                   action1, outcome1, action2, outcome2, float(reward), \n",
    "                   y_predicted[0], d_test, experimenter2.exploration_rate ])\n",
    "    total_reward_list.append(env.total_reward)\n",
    "   \n",
    "    # First part of the loop ...-...........................................\n",
    "    \n",
    "    # Store the ending state of the previous episode\n",
    "    old_state =  np.append(to_categorical(action1, 5), [outcome1])\n",
    "    # Restart the mass of the environment\n",
    "    env.restart_mass()\n",
    "    # Get the new action of experimenter 1 and its resulting outcome\n",
    "    action1 = experimenter1.get_next_action()\n",
    "    outcome1 = env.take_action(action1)\n",
    "    # Store the new state in a variable\n",
    "    current_state = np.append(to_categorical(action1, 5), [outcome1])\n",
    "    # We use the old_state and the current_state to train the experimenter 2.\n",
    "    # We can understand this as the experimenter2 being a traditional RL \n",
    "    # agent interacting with an environment whose states consists on the\n",
    "    # action and outcome of the experimenter 1.\n",
    "    experimenter2.online_train(old_state, action2, reward, current_state)\n",
    "    # Let the experimenter 2 take a new action and store its outcome\n",
    "    action2 = experimenter2.get_next_action(state=current_state)\n",
    "    outcome2 = env.take_action(action2)\n",
    "    # Do a test shooting to train the analyzer\n",
    "    v_train, d_train = env.test_shooting()\n",
    "    measurements = env.get_measurements(action1, outcome1, action2, outcome2,\n",
    "                                         v_train)\n",
    "    X_train, y_train = env.reshape_for_analyzer(measurements, d_train) \n",
    "    analyzer.train(X_train, y_train)\n",
    "    \n",
    "    # Do another test shooting to test the performance of the analyer and\n",
    "    # generate the reward.\n",
    "    v_test, d_test = env.test_shooting()\n",
    "    measurements = env.get_measurements(action1,outcome1, action2, outcome2,\n",
    "                                         v_test)\n",
    "    X_test, y_test = env.reshape_for_analyzer(measurements, d_test)\n",
    "    \n",
    "    # Predict value for the position of the mass \"d\" and generate reward.\n",
    "    y_predicted = analyzer.predict(X_test)[0]\n",
    "    reward = env.give_reward(y_predicted, d_test)\n",
    "    \n",
    "    # Use the reward to train the first experimenter.\n",
    "    experimenter1.update(action1, reward)\n",
    "\n",
    "# Display training status....................................................\n",
    "    count = count + 1\n",
    "    refresh_rate = 2500\n",
    "    if count % (N_Episodes/refresh_rate) == 0:\n",
    "        clear_output()\n",
    "        t2 = time.time()\n",
    "        m, s = divmod(t2-t1, 60)\n",
    "        mt, st = divmod(t2-t0, 60)\n",
    "        me, se = divmod(((t2-t0)/count)*N_Episodes, 60)\n",
    "        mr, sr = divmod(((t2-t0)/count)*N_Episodes-t2+t0, 60)\n",
    "        print (str(int(count)) + '/' +  str(N_Episodes) + \" episodes\" + \n",
    "               '(' + str(100*count/N_Episodes)+ '%)')\n",
    "        print('Elapsed time: {} min {}s'.format(int(mt), int(st)))\n",
    "        print(\"\"\"Est. completion time: {} min {}s,\n",
    "        Est. remaining time: {} min {}s\"\"\".format(int(me), int(se), int(mr),\n",
    "                                                  int(sr)))\n",
    "        t1 = time.time()\n",
    "print('Training completed!')\n",
    "\n",
    "\n",
    "plt.plot(range(len(total_reward_list)), total_reward_list)\n",
    "plt.ylabel(\"Cumulative reward\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df=pd.DataFrame(values, columns = ['Zone', 'Exact position', 'Action 1', \n",
    "                                   'Outcome 1', 'Action 2', 'Outcome 2', \n",
    "                                   'Reward', 'd_predicted', 'd_test', \n",
    "                                   'Exploration rate'])\n",
    "df.to_csv('data-TSS.csv')\n",
    "df.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "184cdf6e-8a67-43e9-8238-48f1530b039f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "333.212px",
    "left": "1540.32px",
    "right": "20px",
    "top": "64px",
    "width": "561.771px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}